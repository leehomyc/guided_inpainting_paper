%!TEX root = guided_inpainting_paper.tex
\section{Related Work}

\noindent\textbf{Deep image generation and manipulation} Generative Adversarial Network (GAN)~\cite{goodfellow2014generative} uses a mini-max two-player game to alternatively train a generator and a discriminator, and has shown impressive capacity to generate natural and high-quality images. However, for the vanilla GANs, the training instability makes it hard to scale to higher resolution images. Several techniques have been proposed to stabilize the training process, including Laplacian pyramid GAN~\cite{denton2015deep}, DCGAN~\cite{radford2015unsupervised}, energy-based GAN~\cite{zhao2016energy}, Wasserstein GAN (WGAN)~\cite{arjovsky2017wasserstein}, WGAN-GP~\cite{gulrajani2017improved} and the Progressive GAN~\cite{karras2017progressive}. Both BTGMI and Progressive GAN gradually increase the depth of the network during training. While Progressive GAN addresses the image synthesis problem, our architecture poses as an ideal candidate for image translation tasks. A major model difference between BTGMI and Progressive GAN is that, rather than bringing in convolutional layers at the end of the network, we progressively insert residual blocks before the upsampling layers. 

Adversarial training, as a general idea for DNN based methods, has been widely applied to various research fields, especially many image editing tasks such as image super-resolution~\cite{kim2016accurate,dong2014learning,ledig2016photo}, image-to-image translation~\cite{isola2016image,zhu2017unpaired}, image inpainting and image harmonization. Recently,~\cite{wang2017high} proposes the Pix2Pix HD model for high-resolution image synthesis using conditional GANs, which produces very high-quality simulated images from semantic maps, human sketches, etc. Our ResNet head simplifies the Pix2Pix HD model and also improves the synthesis quality by re-designing its losses. For the image inpainting task, many DNN based approaches achieve good performance by different network topology and training procedure ~\cite{pathak2016context,yang2017high,yeh2016semantic,iizuka2017globally}. Image harmonization, on the other hand, aims to adjust the appearances of the foreground and background regions such that they are compatible and the composition is realistic. In~\cite{zhu2015learning}, Zhu et al. trains a CNN model to measure how realistic of a composite image is, and uses this metric to adjust and optimize the appearance of the foreground region. Tsai et al.~\cite{tsai2017deep} also proposes a DNN based method by training a deep CNN to learn and predict the context and semantic information of composite images. However, the limitation of image harmonization alone is that low-level appearance or color adjustments are often inadequate to make the composition realistic. In contrast, our approach of guided inpainting not only adjusts the appearance of the guidance patch, but also synthesizes new contents to fill in the gaps and smoothes the transition between the foreground and the background.

\noindent\textbf{Non-neural image inpainting and harmonization} Traditional image completion algorithms can be either diffusion-based~\cite{bertalmio2000image,elad2005simultaneous} or patch-based~\cite{bertalmio2003simultaneous,barnes2009patchmatch}. Diffusion-based methods usually cannot synthesize plausible contents for large holes or textures, due to the fact that it only propagates low-level features. Patch-based methods, however, largely rely on the assumption that the desired patches exist in the database. For harmonization, traditional methods usually apply color and tone matching, by matching global statistics~\cite{reinhard2001color} or multi-scale statistics~\cite{sunkavalli2010multi}, extracting gradient domain information~\cite{perez2003poisson,tao2010error}, or utilizing semantic clues~\cite{tsai2016sky}.~\cite{johnson2011cg2real} further develops a data-driven method, which searches and retrieves multiple real images with similar structural layouts and use them to transfer the appearances. A complete comparison with non-neural inpainting and harmonization algorithms is beyond the scope of our paper.
