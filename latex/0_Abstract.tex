%!TEX root = guided_inpainting_paper.tex
\begin{abstract}
Recent advances in deep generative models have shown promising potential in image inpanting, which is the task of predicting missing pixel values of an image using surrounding context. However, such models are either slow or fail to generate large hole contents. We present a new method for synthesizing high-quality photo-realistic inpaintings from incomplete images using conditional generative adversarial networks (conditional GANs). In particular, we introduce a block-wise procedural training scheme, in conjunction with an annealed adversarial loss, to stabilize the training process of a very deep generative network. We also discuss the effectiveness of a novel patch perceptual loss and multi-scale patch adversarial loss as loss functions. Finally, we extend our framework to several real-world scenarios, including object removal and guided inpainting. Extensive experiments and user-study show that our method significantly outperforms existing methods in all these tasks.
\keywords{deep generative model, image inpainting, image harmonization, image composition.}
\end{abstract}