%!TEX root = guided_inpainting_paper.tex
\begin{abstract}
Recent advances in deep generative models have shown promising potential in predicting missing pixel values in an image using surrounding context. However, such models are either slow or fail to generate large hole contents. We present a new method for synthesizing high-quality photo-realistic inpaintings from incomplete images using conditional generative adversarial networks (conditional GANs). In particular, we introduce a block-wise training scheme, in conjunction with an annealed adversarial loss, to stabilize the training process of a very deep generative network. We also discuss the effectiveness of a novel perceptual similarity metric as an additional loss. Furthermore, we extend our framework to various inpainting scenarios, including object removal, image harmonization and guided inpainting. Extensive experiments and user-studies show that our method significantly outperforms existing methods in all these tasks.
\keywords{Image translation, image inpainting, image harmonization and image composition.}
\end{abstract}